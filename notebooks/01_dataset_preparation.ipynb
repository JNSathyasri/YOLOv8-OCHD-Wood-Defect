{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae4ea05-a08a-4a1e-b3d9-41e4818cb82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLOv8-OCHD: Wood Surface Defect Detection\n",
    "\n",
    "This notebook prepares the dataset used for training and evaluation of:\n",
    "- YOLOv8n (baseline)\n",
    "- O\n",
    "- OC\n",
    "- OCH\n",
    "- OCHD (DyHead)\n",
    "\n",
    "Dataset:\n",
    "- Source: iluvvatar/wood_surface_defects (Hugging Face)\n",
    "- Total images: 20,276\n",
    "- Classes: 10 wood surface defect categories\n",
    "\n",
    "This notebook:\n",
    "1. Loads the dataset\n",
    "2. Converts annotations to YOLO format\n",
    "3. Splits data into train/validation\n",
    "4. Visualizes bounding boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24138c48-410e-4f75-9890-bf4ff636809d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\YOLOv8_OCHD_Project\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.9.1+cu126\n",
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 4050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3463ad45-7db8-4483-8afc-af09c9f0a156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Quartzity': 0,\n",
       " 'Live_Knot': 1,\n",
       " 'Marrow': 2,\n",
       " 'Resin': 3,\n",
       " 'Dead_Knot': 4,\n",
       " 'Knot_with_Crack': 5,\n",
       " 'Knot_missing': 6,\n",
       " 'Crack': 7,\n",
       " 'Blue_Stain': 8,\n",
       " 'Overgrown': 9}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fixed class mapping (used throughout the project)\n",
    "CLASS_NAMES = [\n",
    "    \"Quartzity\",\n",
    "    \"Live_Knot\",\n",
    "    \"Marrow\",\n",
    "    \"Resin\",\n",
    "    \"Dead_Knot\",\n",
    "    \"Knot_with_Crack\",\n",
    "    \"Knot_missing\",\n",
    "    \"Crack\",\n",
    "    \"Blue_Stain\",\n",
    "    \"Overgrown\",\n",
    "]\n",
    "\n",
    "CLASS_TO_ID = {name: i for i, name in enumerate(CLASS_NAMES)}\n",
    "CLASS_TO_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48a9f221-79b8-40aa-ada6-4c5798f7a5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 20276\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 160300034,\n",
       " 'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=2800x1024>,\n",
       " 'objects': [{'bb': [0.5075, 0.564941, 0.027142, 0.051758],\n",
       "   'label': 'Dead_Knot'}]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"iluvvatar/wood_surface_defects\", split=\"train\")\n",
    "print(\"Total samples:\", len(dataset))\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d72a78e-dc9a-4b02-bff1-3eb1bcc049c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directories ready.\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = \"C:/YOLOv8_OCHD_Project/datasets/wood\"\n",
    "IMG_TRAIN = os.path.join(BASE_DIR, \"images\", \"train\")\n",
    "LBL_TRAIN = os.path.join(BASE_DIR, \"labels\", \"train\")\n",
    "IMG_VAL = os.path.join(BASE_DIR, \"images\", \"val\")\n",
    "LBL_VAL = os.path.join(BASE_DIR, \"labels\", \"val\")\n",
    "\n",
    "for p in [IMG_TRAIN, LBL_TRAIN, IMG_VAL, LBL_VAL]:\n",
    "    os.makedirs(p, exist_ok=True)\n",
    "\n",
    "print(\"Directories ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9a75f9a-5fd2-4208-a24f-dbb8a4be10ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 20276/20276 [07:28<00:00, 45.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO-format dataset created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, sample in tqdm(enumerate(dataset), total=len(dataset)):\n",
    "    # Save image\n",
    "    img_path = os.path.join(IMG_TRAIN, f\"{idx}.jpg\")\n",
    "    sample[\"image\"].save(img_path)\n",
    "\n",
    "    # Save label\n",
    "    label_path = os.path.join(LBL_TRAIN, f\"{idx}.txt\")\n",
    "    with open(label_path, \"w\") as f:\n",
    "        for obj in sample[\"objects\"]:\n",
    "            cls_name = obj[\"label\"]\n",
    "            if cls_name not in CLASS_TO_ID:\n",
    "                continue\n",
    "\n",
    "            cls_id = CLASS_TO_ID[cls_name]\n",
    "            cx, cy, w, h = obj[\"bb\"]  # YOLO normalized\n",
    "\n",
    "            f.write(f\"{cls_id} {cx} {cy} {w} {h}\\n\")\n",
    "\n",
    "print(\"YOLO-format dataset created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45f15e28-63b8-40a9-95a5-c7d17d7e5274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images: 16220\n",
      "Val images: 4056\n"
     ]
    }
   ],
   "source": [
    "all_images = [f for f in os.listdir(IMG_TRAIN) if f.endswith(\".jpg\")]\n",
    "random.shuffle(all_images)\n",
    "\n",
    "split_idx = int(0.8 * len(all_images))\n",
    "train_files = all_images[:split_idx]\n",
    "val_files = all_images[split_idx:]\n",
    "\n",
    "def move(files, img_dst, lbl_dst):\n",
    "    for f in files:\n",
    "        os.replace(\n",
    "            os.path.join(IMG_TRAIN, f),\n",
    "            os.path.join(img_dst, f)\n",
    "        )\n",
    "        os.replace(\n",
    "            os.path.join(LBL_TRAIN, f.replace(\".jpg\", \".txt\")),\n",
    "            os.path.join(lbl_dst, f.replace(\".jpg\", \".txt\"))\n",
    "        )\n",
    "\n",
    "move(train_files, IMG_TRAIN, LBL_TRAIN)\n",
    "move(val_files, IMG_VAL, LBL_VAL)\n",
    "\n",
    "print(\"Train images:\", len(train_files))\n",
    "print(\"Val images:\", len(val_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "139ce9fa-670e-433c-8408-bf32c0aff070",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_imgs = random.sample(os.listdir(IMG_TRAIN), 3)\n",
    "\n",
    "for img_name in sample_imgs:\n",
    "    img = cv2.imread(os.path.join(IMG_TRAIN, img_name))\n",
    "    h, w, _ = img.shape\n",
    "\n",
    "    with open(os.path.join(LBL_TRAIN, img_name.replace(\".jpg\", \".txt\"))) as f:\n",
    "        for line in f:\n",
    "            cls, cx, cy, bw, bh = map(float, line.split())\n",
    "            cx, cy = int(cx * w), int(cy * h)\n",
    "            bw, bh = int(bw * w), int(bh * h)\n",
    "\n",
    "            x1 = int(cx - bw / 2)\n",
    "            y1 = int(cy - bh / 2)\n",
    "            x2 = int(cx + bw / 2)\n",
    "            y2 = int(cy + bh / 2)\n",
    "\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (0,255,0), 2)\n",
    "            cv2.putText(img, CLASS_NAMES[int(cls)], (x1, y1-5),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,0), 2)\n",
    "\n",
    "    cv2.imshow(\"Sample\", img)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd3a9e3-1e8c-4e9e-9cde-a564cbe53d08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "YOLOv8-OCHD",
   "language": "python",
   "name": "yolov8_ochd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
